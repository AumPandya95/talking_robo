{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0e3cb4-6b79-4d65-872b-8e0a763f8370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = os.path.join(Path.cwd().parent, \".env\")\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce78146-82c6-453f-b8c4-fdf6001f17ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aum/Desktop/Programming/llm/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ac4857-b465-4f88-9f3f-63d2cf162f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9717d5ce-1ace-40f5-9c46-f71abfe4903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.46s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\",\n",
    "                                          device_map=\"auto\",\n",
    "                                          token=os.environ.get(\"hugging_face_token\"))\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\",\n",
    "                                             device_map=\"auto\",\n",
    "                                             token=os.environ.get(\"hugging_face_token\"),\n",
    "                                             use_cache=False\n",
    "                                             # quantization_config=quantization_config\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f71ba4-a8c9-4bba-a976-ee0a5a3a5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d71c8c2-0248-470d-bf89-1419f6ef9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**input_ids, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e2cfbd-4505-48c0-a976-3639c1641733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about Machine Learning.\n",
      "\n",
      "Machines, they weave and they learn,\n",
      "From the data, they discern.\n",
      "Algorithms, a symphony,\n",
      "Unleash the power of the machine.\n",
      "\n",
      "With each iteration, they grow,\n",
      "A tapestry of insights they sow.\n",
      "From the past, they learn and they adapt,\n",
      "A never-ending, ever-fast.\n",
      "\n",
      "The future holds mysteries untold,\n",
      "Where machines will shape our world.\n",
      "They will heal, they will fight, they will play,\n",
      "A symphony of the digital day.\n",
      "\n",
      "So let the machines learn and let them soar,\n",
      "For the future is here, and it's here to stay.\n",
      "With a touch of humanity, a spark of care,\n",
      "We embrace the machine, and we share.<eos>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ed03d-fcf1-4a05-8d96-e1e3dccf0a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
